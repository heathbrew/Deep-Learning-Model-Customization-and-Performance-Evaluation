{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8bf15b99-e25b-47cb-b22c-66fdfdcd149b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36f70d52-9ecb-4991-953b-4e936e6cd5d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\Desktop\\\\Deep Learning\\\\Lab 7\\\\Deep-Learning-Model-Customization-and-Performance-Evaluation\\\\Research\\\\Cifar10'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee595830-35da-4eba-89c3-4e5d43cf18b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../\")\n",
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53cf3a64-a584-4c04-9ba4-80171a3b8da5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\Desktop\\\\Deep Learning\\\\Lab 7\\\\Deep-Learning-Model-Customization-and-Performance-Evaluation'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92b1c09e-0d33-4676-a107-8dc718cdfd37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from pathlib import Path\n",
    "logging.basicConfig(\n",
    "    # filename='extract_data.log',\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    datefmt='%Y-%m-%d %H:%M:%S'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8a87d1a-3388-4be3-9f78-2690267982cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Desktop\\Deep Learning\\Lab 7\\Deep-Learning-Model-Customization-and-Performance-Evaluation\n"
     ]
    }
   ],
   "source": [
    "print(Path(os.getcwd()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1368b49f-2bc4-4e9a-9588-baf9c1c98109",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-08 17:56:34 - INFO - Loading and preprocessing CIFAR-10 dataset...\n",
      "2024-04-08 17:56:35 - INFO - Label Encoder saved to D:\\Desktop\\Deep Learning\\Lab 7\\Deep-Learning-Model-Customization-and-Performance-Evaluation\\ModelExperiments\\Cifar10\\label_encoder.pkl\n",
      "2024-04-08 17:56:36 - INFO - Number of unique classes in y: 10\n",
      "2024-04-08 17:56:36 - INFO - Unique classes in y: [0 1 2 3 4 5 6 7 8 9]\n",
      "2024-04-08 17:56:36 - INFO - Counts of each class in y: [6000 6000 6000 6000 6000 6000 6000 6000 6000 6000]\n",
      "2024-04-08 17:56:36 - INFO - Average frequency of all classes: 6000.0\n",
      "2024-04-08 17:56:36 - INFO - Minimum frequency among classes: 6000\n",
      "2024-04-08 17:56:36 - INFO - Class 0 reduced to 6000 instances for balancing.\n",
      "2024-04-08 17:56:36 - INFO - Class 1 reduced to 6000 instances for balancing.\n",
      "2024-04-08 17:56:36 - INFO - Class 2 reduced to 6000 instances for balancing.\n",
      "2024-04-08 17:56:36 - INFO - Class 3 reduced to 6000 instances for balancing.\n",
      "2024-04-08 17:56:36 - INFO - Class 4 reduced to 6000 instances for balancing.\n",
      "2024-04-08 17:56:36 - INFO - Class 5 reduced to 6000 instances for balancing.\n",
      "2024-04-08 17:56:36 - INFO - Class 6 reduced to 6000 instances for balancing.\n",
      "2024-04-08 17:56:36 - INFO - Class 7 reduced to 6000 instances for balancing.\n",
      "2024-04-08 17:56:36 - INFO - Class 8 reduced to 6000 instances for balancing.\n",
      "2024-04-08 17:56:36 - INFO - Class 9 reduced to 6000 instances for balancing.\n",
      "2024-04-08 17:56:37 - INFO - Number of rows in the balanced dataset: 60000\n",
      "2024-04-08 17:56:43 - INFO - X_train data saved to D:\\Desktop\\Deep Learning\\Lab 7\\Deep-Learning-Model-Customization-and-Performance-Evaluation\\Dataset\\Modeltraining\\Cifar10\\X_train.npy\n",
      "2024-04-08 17:56:43 - INFO - y_train data saved to D:\\Desktop\\Deep Learning\\Lab 7\\Deep-Learning-Model-Customization-and-Performance-Evaluation\\Dataset\\Modeltraining\\Cifar10\\y_train.npy\n",
      "2024-04-08 17:56:45 - INFO - X_test data saved to D:\\Desktop\\Deep Learning\\Lab 7\\Deep-Learning-Model-Customization-and-Performance-Evaluation\\Dataset\\Modeltraining\\Cifar10\\X_test.npy\n",
      "2024-04-08 17:56:45 - INFO - y_test data saved to D:\\Desktop\\Deep Learning\\Lab 7\\Deep-Learning-Model-Customization-and-Performance-Evaluation\\Dataset\\Modeltraining\\Cifar10\\y_test.npy\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import os\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from joblib import dump\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "@dataclass\n",
    "class DataTransformationConfig:\n",
    "    root_dir: Path\n",
    "    X_train_file: Path\n",
    "    y_train_file: Path\n",
    "    X_test_file: Path\n",
    "    y_test_file: Path\n",
    "    label_encoder_file: Path  # Added this line\n",
    "\n",
    "\n",
    "class ConfigurationManager:\n",
    "    def __init__(self):\n",
    "        self.root_dir = Path(os.getcwd())\n",
    "        self.X_train_file = self.root_dir / \"Dataset/Modeltraining/Cifar10/X_train.npy\"\n",
    "        self.y_train_file = self.root_dir / \"Dataset/Modeltraining/Cifar10/y_train.npy\"\n",
    "        self.X_test_file = self.root_dir / \"Dataset/Modeltraining/Cifar10/X_test.npy\"\n",
    "        self.y_test_file = self.root_dir / \"Dataset/Modeltraining/Cifar10/y_test.npy\"\n",
    "        self.experiment_results_dir = self.root_dir / \"ModelExperiments/Cifar10\"\n",
    "        self.label_encoder_file = self.experiment_results_dir / \"label_encoder.pkl\"  # Adjusted path\n",
    "\n",
    "    def get_data_transformation_config(self) -> DataTransformationConfig:\n",
    "        return DataTransformationConfig(\n",
    "            root_dir=self.root_dir,\n",
    "            X_train_file=self.X_train_file,\n",
    "            y_train_file=self.y_train_file,\n",
    "            X_test_file=self.X_test_file,\n",
    "            y_test_file=self.y_test_file,\n",
    "            label_encoder_file=self.label_encoder_file\n",
    "        )\n",
    "\n",
    "class DataTransformation:\n",
    "    def __init__(self, config: DataTransformationConfig):\n",
    "        self.config = config\n",
    "\n",
    "    def ensure_directories_exist(self):\n",
    "        \"\"\"Ensure that directories for all file paths exist.\"\"\"\n",
    "        for path in [self.config.X_train_file, self.config.y_train_file, self.config.X_test_file, self.config.y_test_file]:\n",
    "            path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    def encode_labels(self, y_train, y_test):\n",
    "        # Convert one-hot encoded labels to 1D format\n",
    "        y_train_1d = np.argmax(y_train, axis=1)\n",
    "        y_test_1d = np.argmax(y_test, axis=1)\n",
    "        \n",
    "        # Convert y_train and y_test to label encoded format\n",
    "        label_encoder = LabelEncoder()\n",
    "        y_train_encoded = label_encoder.fit_transform(y_train_1d)\n",
    "        y_test_encoded = label_encoder.transform(y_test_1d)\n",
    "        \n",
    "        # Save the label encoder for later use\n",
    "        dump(label_encoder, self.config.label_encoder_file)\n",
    "        logging.info(f\"Label Encoder saved to {self.config.label_encoder_file}\")\n",
    "        \n",
    "        return y_train_encoded, y_test_encoded\n",
    "        \n",
    "        return y_train_encoded, y_test_encoded\n",
    "            \n",
    "    def ensure_uniform_class_distribution(self, X, y):\n",
    "        unique, counts = np.unique(y, return_counts=True)\n",
    "        min_count = np.min(counts)\n",
    "        avg_count = np.mean(counts)\n",
    "    \n",
    "        # Logging the details about class distributions\n",
    "        logging.info(f\"Number of unique classes in y: {len(unique)}\")\n",
    "        logging.info(f\"Unique classes in y: {unique}\")\n",
    "        logging.info(f\"Counts of each class in y: {counts}\")\n",
    "        logging.info(f\"Average frequency of all classes: {avg_count}\")\n",
    "        logging.info(f\"Minimum frequency among classes: {min_count}\")\n",
    "    \n",
    "        X_list = []\n",
    "        y_list = []\n",
    "        for class_value in unique:\n",
    "            class_indices = np.where(y == class_value)[0]\n",
    "            np.random.shuffle(class_indices)\n",
    "            selected_indices = class_indices[:min_count]\n",
    "            X_list.append(X[selected_indices, :])\n",
    "            y_list.append(y[selected_indices])\n",
    "    \n",
    "            # Logging details about data removal for balancing\n",
    "            logging.info(f\"Class {class_value} reduced to {min_count} instances for balancing.\")\n",
    "    \n",
    "        X_balanced = np.concatenate(X_list, axis=0)\n",
    "        y_balanced = np.concatenate(y_list, axis=0)\n",
    "    \n",
    "        # Shuffling the data to mix the classes\n",
    "        indices = np.arange(X_balanced.shape[0])\n",
    "        np.random.shuffle(indices)\n",
    "        X_balanced = X_balanced[indices]\n",
    "        y_balanced = y_balanced[indices]\n",
    "    \n",
    "        # Logging final dataset size after balancing\n",
    "        logging.info(f\"Number of rows in the balanced dataset: {X_balanced.shape[0]}\")\n",
    "    \n",
    "        return X_balanced, y_balanced\n",
    "\n",
    "    def train_test_splitting(self):\n",
    "\n",
    "        self.ensure_directories_exist()\n",
    "        \n",
    "        # Ensure the directory for the status file exists\n",
    "        self.config.root_dir.mkdir(parents=True, exist_ok=True)  # This line ensures that the root directory exists\n",
    "\n",
    "        # Load and preprocess CIFAR-10 dataset\n",
    "        logging.info(\"Loading and preprocessing CIFAR-10 dataset...\")\n",
    "        (X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "        X_train, X_test = X_train / 255.0, X_test / 255.0\n",
    "        y_train, y_test = to_categorical(y_train, 10), to_categorical(y_test, 10)\n",
    "\n",
    "        # Call the function to encode labels\n",
    "        y_train_encoded, y_test_encoded = self.encode_labels(y_train, y_test)\n",
    "\n",
    "        # Combine X_train and X_test to create X\n",
    "        X = np.concatenate((X_train, X_test), axis=0)\n",
    "        \n",
    "        # Combine y_train and y_test to create y\n",
    "        y = np.concatenate((y_train_encoded, y_test_encoded), axis=0)\n",
    "\n",
    "        # Normalize pixel values to be between 0 and 1\n",
    "        # X = X / 255.0\n",
    "\n",
    "        # Ensure uniform class distribution\n",
    "        X_balanced, y_balanced = self.ensure_uniform_class_distribution(X, y)\n",
    "\n",
    "        # Split the dataset into training and testing sets\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X_balanced, y_balanced, test_size=0.2, random_state=42)\n",
    "\n",
    "        # Save the split data as numpy files\n",
    "        np.save(self.config.X_train_file, X_train)\n",
    "        logging.info(f\"X_train data saved to {self.config.X_train_file}\")\n",
    "        np.save(self.config.y_train_file, y_train)\n",
    "        logging.info(f\"y_train data saved to {self.config.y_train_file}\")\n",
    "        np.save(self.config.X_test_file, X_test)\n",
    "        logging.info(f\"X_test data saved to {self.config.X_test_file}\")\n",
    "        np.save(self.config.y_test_file, y_test)\n",
    "        logging.info(f\"y_test data saved to {self.config.y_test_file}\")\n",
    "\n",
    "def main():\n",
    "    config_manager = ConfigurationManager()\n",
    "    data_transformation_config = config_manager.get_data_transformation_config()\n",
    "    data_transformation = DataTransformation(data_transformation_config)\n",
    "    data_transformation.train_test_splitting()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "416e6d2a-4d42-49cc-8d2b-cbab0fcc9355",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>3062</th>\n",
       "      <th>3063</th>\n",
       "      <th>3064</th>\n",
       "      <th>3065</th>\n",
       "      <th>3066</th>\n",
       "      <th>3067</th>\n",
       "      <th>3068</th>\n",
       "      <th>3069</th>\n",
       "      <th>3070</th>\n",
       "      <th>3071</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.670588</td>\n",
       "      <td>0.678431</td>\n",
       "      <td>0.635294</td>\n",
       "      <td>0.678431</td>\n",
       "      <td>0.686275</td>\n",
       "      <td>0.643137</td>\n",
       "      <td>0.709804</td>\n",
       "      <td>0.717647</td>\n",
       "      <td>0.674510</td>\n",
       "      <td>0.741176</td>\n",
       "      <td>...</td>\n",
       "      <td>0.505882</td>\n",
       "      <td>0.439216</td>\n",
       "      <td>0.431373</td>\n",
       "      <td>0.380392</td>\n",
       "      <td>0.435294</td>\n",
       "      <td>0.423529</td>\n",
       "      <td>0.376471</td>\n",
       "      <td>0.349020</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.298039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.443137</td>\n",
       "      <td>0.298039</td>\n",
       "      <td>0.019608</td>\n",
       "      <td>0.396078</td>\n",
       "      <td>0.298039</td>\n",
       "      <td>0.047059</td>\n",
       "      <td>0.270588</td>\n",
       "      <td>0.227451</td>\n",
       "      <td>0.050980</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>...</td>\n",
       "      <td>0.078431</td>\n",
       "      <td>0.113725</td>\n",
       "      <td>0.113725</td>\n",
       "      <td>0.031373</td>\n",
       "      <td>0.098039</td>\n",
       "      <td>0.070588</td>\n",
       "      <td>0.011765</td>\n",
       "      <td>0.101961</td>\n",
       "      <td>0.070588</td>\n",
       "      <td>0.023529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.745098</td>\n",
       "      <td>0.650980</td>\n",
       "      <td>0.552941</td>\n",
       "      <td>0.709804</td>\n",
       "      <td>0.611765</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.701961</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.725490</td>\n",
       "      <td>...</td>\n",
       "      <td>0.631373</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.745098</td>\n",
       "      <td>0.713725</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>0.694118</td>\n",
       "      <td>0.698039</td>\n",
       "      <td>0.854902</td>\n",
       "      <td>0.654902</td>\n",
       "      <td>0.658824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.819608</td>\n",
       "      <td>0.552941</td>\n",
       "      <td>0.811765</td>\n",
       "      <td>0.819608</td>\n",
       "      <td>0.541176</td>\n",
       "      <td>0.827451</td>\n",
       "      <td>0.815686</td>\n",
       "      <td>0.541176</td>\n",
       "      <td>0.831373</td>\n",
       "      <td>...</td>\n",
       "      <td>0.254902</td>\n",
       "      <td>0.627451</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.325490</td>\n",
       "      <td>0.658824</td>\n",
       "      <td>0.576471</td>\n",
       "      <td>0.349020</td>\n",
       "      <td>0.623529</td>\n",
       "      <td>0.517647</td>\n",
       "      <td>0.290196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.070588</td>\n",
       "      <td>0.223529</td>\n",
       "      <td>0.047059</td>\n",
       "      <td>0.090196</td>\n",
       "      <td>0.282353</td>\n",
       "      <td>0.054902</td>\n",
       "      <td>0.101961</td>\n",
       "      <td>0.298039</td>\n",
       "      <td>0.062745</td>\n",
       "      <td>0.094118</td>\n",
       "      <td>...</td>\n",
       "      <td>0.188235</td>\n",
       "      <td>0.392157</td>\n",
       "      <td>0.403922</td>\n",
       "      <td>0.141176</td>\n",
       "      <td>0.337255</td>\n",
       "      <td>0.364706</td>\n",
       "      <td>0.121569</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.184314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47995</th>\n",
       "      <td>0.580392</td>\n",
       "      <td>0.615686</td>\n",
       "      <td>0.619608</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.556863</td>\n",
       "      <td>0.552941</td>\n",
       "      <td>0.596078</td>\n",
       "      <td>0.592157</td>\n",
       "      <td>0.611765</td>\n",
       "      <td>0.611765</td>\n",
       "      <td>...</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.443137</td>\n",
       "      <td>0.611765</td>\n",
       "      <td>0.560784</td>\n",
       "      <td>0.537255</td>\n",
       "      <td>0.682353</td>\n",
       "      <td>0.662745</td>\n",
       "      <td>0.490196</td>\n",
       "      <td>0.619608</td>\n",
       "      <td>0.584314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47996</th>\n",
       "      <td>0.137255</td>\n",
       "      <td>0.223529</td>\n",
       "      <td>0.121569</td>\n",
       "      <td>0.180392</td>\n",
       "      <td>0.231373</td>\n",
       "      <td>0.141176</td>\n",
       "      <td>0.090196</td>\n",
       "      <td>0.125490</td>\n",
       "      <td>0.043137</td>\n",
       "      <td>0.258824</td>\n",
       "      <td>...</td>\n",
       "      <td>0.309804</td>\n",
       "      <td>0.345098</td>\n",
       "      <td>0.498039</td>\n",
       "      <td>0.368627</td>\n",
       "      <td>0.207843</td>\n",
       "      <td>0.337255</td>\n",
       "      <td>0.196078</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.392157</td>\n",
       "      <td>0.247059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47997</th>\n",
       "      <td>0.737255</td>\n",
       "      <td>0.776471</td>\n",
       "      <td>0.843137</td>\n",
       "      <td>0.721569</td>\n",
       "      <td>0.772549</td>\n",
       "      <td>0.835294</td>\n",
       "      <td>0.721569</td>\n",
       "      <td>0.784314</td>\n",
       "      <td>0.843137</td>\n",
       "      <td>0.721569</td>\n",
       "      <td>...</td>\n",
       "      <td>0.329412</td>\n",
       "      <td>0.631373</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.301961</td>\n",
       "      <td>0.603922</td>\n",
       "      <td>0.513725</td>\n",
       "      <td>0.274510</td>\n",
       "      <td>0.619608</td>\n",
       "      <td>0.537255</td>\n",
       "      <td>0.286275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47998</th>\n",
       "      <td>0.839216</td>\n",
       "      <td>0.784314</td>\n",
       "      <td>0.713725</td>\n",
       "      <td>0.803922</td>\n",
       "      <td>0.745098</td>\n",
       "      <td>0.698039</td>\n",
       "      <td>0.796078</td>\n",
       "      <td>0.737255</td>\n",
       "      <td>0.686275</td>\n",
       "      <td>0.827451</td>\n",
       "      <td>...</td>\n",
       "      <td>0.709804</td>\n",
       "      <td>0.890196</td>\n",
       "      <td>0.803922</td>\n",
       "      <td>0.725490</td>\n",
       "      <td>0.905882</td>\n",
       "      <td>0.819608</td>\n",
       "      <td>0.745098</td>\n",
       "      <td>0.894118</td>\n",
       "      <td>0.811765</td>\n",
       "      <td>0.733333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47999</th>\n",
       "      <td>0.694118</td>\n",
       "      <td>0.784314</td>\n",
       "      <td>0.960784</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.756863</td>\n",
       "      <td>0.929412</td>\n",
       "      <td>0.674510</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.937255</td>\n",
       "      <td>0.670588</td>\n",
       "      <td>...</td>\n",
       "      <td>0.658824</td>\n",
       "      <td>0.356863</td>\n",
       "      <td>0.556863</td>\n",
       "      <td>0.662745</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.549020</td>\n",
       "      <td>0.658824</td>\n",
       "      <td>0.356863</td>\n",
       "      <td>0.556863</td>\n",
       "      <td>0.662745</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48000 rows × 3072 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6     \\\n",
       "0      0.670588  0.678431  0.635294  0.678431  0.686275  0.643137  0.709804   \n",
       "1      0.443137  0.298039  0.019608  0.396078  0.298039  0.047059  0.270588   \n",
       "2      0.745098  0.650980  0.552941  0.709804  0.611765  0.529412  0.701961   \n",
       "3      0.800000  0.819608  0.552941  0.811765  0.819608  0.541176  0.827451   \n",
       "4      0.070588  0.223529  0.047059  0.090196  0.282353  0.054902  0.101961   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "47995  0.580392  0.615686  0.619608  0.533333  0.556863  0.552941  0.596078   \n",
       "47996  0.137255  0.223529  0.121569  0.180392  0.231373  0.141176  0.090196   \n",
       "47997  0.737255  0.776471  0.843137  0.721569  0.772549  0.835294  0.721569   \n",
       "47998  0.839216  0.784314  0.713725  0.803922  0.745098  0.698039  0.796078   \n",
       "47999  0.694118  0.784314  0.960784  0.666667  0.756863  0.929412  0.674510   \n",
       "\n",
       "           7         8         9     ...      3062      3063      3064  \\\n",
       "0      0.717647  0.674510  0.741176  ...  0.505882  0.439216  0.431373   \n",
       "1      0.227451  0.050980  0.176471  ...  0.078431  0.113725  0.113725   \n",
       "2      0.600000  0.529412  0.725490  ...  0.631373  0.941176  0.745098   \n",
       "3      0.815686  0.541176  0.831373  ...  0.254902  0.627451  0.533333   \n",
       "4      0.298039  0.062745  0.094118  ...  0.188235  0.392157  0.403922   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "47995  0.592157  0.611765  0.611765  ...  0.529412  0.443137  0.611765   \n",
       "47996  0.125490  0.043137  0.258824  ...  0.309804  0.345098  0.498039   \n",
       "47997  0.784314  0.843137  0.721569  ...  0.329412  0.631373  0.533333   \n",
       "47998  0.737255  0.686275  0.827451  ...  0.709804  0.890196  0.803922   \n",
       "47999  0.764706  0.937255  0.670588  ...  0.658824  0.356863  0.556863   \n",
       "\n",
       "           3065      3066      3067      3068      3069      3070      3071  \n",
       "0      0.380392  0.435294  0.423529  0.376471  0.349020  0.333333  0.298039  \n",
       "1      0.031373  0.098039  0.070588  0.011765  0.101961  0.070588  0.023529  \n",
       "2      0.713725  0.882353  0.694118  0.698039  0.854902  0.654902  0.658824  \n",
       "3      0.325490  0.658824  0.576471  0.349020  0.623529  0.517647  0.290196  \n",
       "4      0.141176  0.337255  0.364706  0.121569  0.352941  0.400000  0.184314  \n",
       "...         ...       ...       ...       ...       ...       ...       ...  \n",
       "47995  0.560784  0.537255  0.682353  0.662745  0.490196  0.619608  0.584314  \n",
       "47996  0.368627  0.207843  0.337255  0.196078  0.294118  0.392157  0.247059  \n",
       "47997  0.301961  0.603922  0.513725  0.274510  0.619608  0.537255  0.286275  \n",
       "47998  0.725490  0.905882  0.819608  0.745098  0.894118  0.811765  0.733333  \n",
       "47999  0.662745  0.352941  0.549020  0.658824  0.356863  0.556863  0.662745  \n",
       "\n",
       "[48000 rows x 3072 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Specify the path to your numpy array file\n",
    "npy_file_path = 'Dataset/Modeltraining/Cifar10/X_train.npy'\n",
    "\n",
    "# Load the numpy array file\n",
    "data = np.load(npy_file_path)\n",
    "\n",
    "# Reshape the 4D array into a 2D array\n",
    "num_images = data.shape[0]\n",
    "num_pixels = data.shape[1] * data.shape[2] * data.shape[3]\n",
    "data_reshaped = data.reshape(num_images, num_pixels)\n",
    "\n",
    "# Convert the 2D array to a DataFrame\n",
    "df = pd.DataFrame(data_reshaped)\n",
    "\n",
    "# Display the DataFrame\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "facb0116-c823-49bd-9b6e-f62b0479addb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Specify the path to your numpy array file\n",
    "npy_file_path = 'Dataset/Modeltraining/Cifar10/X_train.npy'\n",
    "\n",
    "# Load the numpy array file\n",
    "data = np.load(npy_file_path)\n",
    "\n",
    "# Reshape the 4D array into a 2D array\n",
    "num_images = data.shape[0]\n",
    "num_pixels = data.shape[1] * data.shape[2] * data.shape[3]\n",
    "data_reshaped = data.reshape(num_images, num_pixels)\n",
    "\n",
    "# Convert the 2D array to a DataFrame\n",
    "df = pd.DataFrame(data_reshaped)\n",
    "\n",
    "# Select a random row number (change this as per your requirement)\n",
    "row_number = 10\n",
    "\n",
    "# Inverse transform the scaled row to get the original image\n",
    "original_image = df.iloc[row_number].values.reshape(32, 32, 3)\n",
    "\n",
    "# Display the image\n",
    "plt.imshow(original_image, cmap=\"gray\")\n",
    "plt.title(f\"row_number: {row_number}\")  # Display the row number as the label\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "109aa9bd-f0fd-4e64-aa5c-4814f27330ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0\n",
       "0  3\n",
       "1  3\n",
       "2  8\n",
       "3  7\n",
       "4  8"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Specify the path to your numpy array file\n",
    "npy_file_path = 'Dataset/Modeltraining/Cifar10/y_train.npy'\n",
    "\n",
    "# Load the numpy array file\n",
    "data = np.load(npy_file_path)\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Display the DataFrame\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5925f97-6f26-4258-9db0-6d40f5bd1f72",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
